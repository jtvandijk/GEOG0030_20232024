# Analysing Spatial Patterns I: Geometric Operations and Spatial Queries
This week, we will be looking at the use of geometric operations and spatial queries within spatial data processing and analysis. Geometric operations and spatial queries are not really a theoretical topic per se but rather essential building blocks to overall spatial data processing and analysis such as calculating the area covered by an individual polygon in an areal unit dataset to running **buffer** and **point-in-polygon** calculations.

## Lecture slides {#slides-w06}
The slides for this week's lecture can be downloaded here: [\[Link\]]({{< var slides.week06 >}})

## Reading list {#reading-w06}
#### Essential readings
- Lovelace, R., Nowosad, J. and Muenchow, J. 2021. Geocomputation with R, **Chapter 4**: *Spatial data operations*. [[Link]](https://geocompr.robinlovelace.net/spatial-operations.html)
- Lovelace, R., Nowosad, J. and Muenchow, J. 2021. Geocomputation with R, **Chapter 5**: *Geometry operations*. [[Link]](https://geocompr.robinlovelace.net/geometry-operations.html)
- Lovelace, R., Nowosad, J. and Muenchow, J. 2021. Geocomputation with R, **Chapter 6**: *Reprojecting geographic data*. [[Link]](https://geocompr.robinlovelace.net/reproj-geo-data.html)

#### Suggested readings
- Houlden, V. *et al.* 2019. A spatial analysis of proximate greenspace and mental wellbeing in London. *Applied Geography* 109: 102036. [[Link]](https://doi.org/10.1016/j.apgeog.2019.102036)
- Malleson, N. and Andresen, M. 2016. Exploring the impact of ambient population measures on London crime hotspots. *Journal of Criminal Justice* 46: 52-63. [[Link]](https://doi.org/10.1016/j.jcrimjus.2016.03.002)

<!--## Map challenge
Before we start with this week's tutorial, we will start with a small formative assessment: a **45-minute map challenge**. During this task you have 45 minutes to create a map using a specific dataset. After 45 minutes you need to stop coding and submit the map online (see details in the instructions). We will go through the submitted maps and provide general feedback to the entire class on what can be improved and on what has been going well.

All instructions can be found here: [[Link]](https://github.com/jtvandijk/GEOG0030/tree/master/data/ppt/GEOG0030_MapChallenge.pdf).-->

## Bike theft in London {#bike-theft-w06}
This week, we will be investigating bike theft in London in 2021 and look to confirm a very simple hypothesis: *that bike theft primarily occurs near tube and train stations.* We will be investigating its distribution across London using the point data provided within our crime dataset. We will then compare this distribution to the location of train and tube stations using specific geometric operations and spatial queries that can compare the geometry of two (or more) datasets. We will also learn how to download data from OpenStreetMap as well as use an interactive version of `tmap` to explore the distribution of the locations of individual bike theft against the locations of these stations.

### Spatial analysis set up {#setup-w05}
Open a new script within your GEOG0030 project and save this script as `wk6-bike-theft-analysis.r`. At the top of your script, add the following metadata:

```{r}
#| label: 06-script-title
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: False
#| filename: "R code"
# Analysing bike theft in London using geometric analysis
# Date: January 2024
# Author: Justin 
```

Now let us add **all** of the libraries we will be using today to the top of our script:

```{r}
#| label: 06-load-libraries
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# load libraries
library(tidyverse)
library(sf)
library(tmap)
library(osmdata)
```

```{r}
#| label: 06-tmap-settings
#| classes: styled-output
#| echo: False
#| warning: False
#| message: False
#| eval: True
# ensure tmap is set to plot
tmap_mode("plot")
```

This week, we will start off using three datasets: the London MSOA boundaries for 2021, recorded crime in London for 2021 from [data.police.uk](https://data.police.uk/), and the locations of the train and tube Stations from [Transport for London](https://tfl.gov.uk/). We already downloaded the crime data for 2021 during [Week 4's computer tutorial](04-statistics.html#crime-data) and we also saved the 2021 London MSOA boundaries [last week](05-spatial.html#spatial-analysis-set-up), so we only need to download a dataset containing train and tube stations in London.

#### File download
| File                     | Type         | Link |
| :------                  | :------      | :------ |
| Train and tube stations in London       | `kml`        | [Download](https://github.com/jtvandijk/GEOG0030/tree/master/data/zip/tfl-stations.zip) |

Once downloaded, move your `tfl_stations.kml` download to your `raw` data folder and create a new `transport` folder to contain it. After this, let's start by loading our London MSOA file:

```{r}
#| label: 06-load-shp
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# read in our MSOA GeoPackage
msoa_london <- st_read("data/raw/boundaries/MSOA2021_London.gpkg")
``` 

Check the **CRS** of our `london_ward_shp` spatial dataframe:

```{r}
#| label: 06-crs-msoapop
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect CRS
st_crs(msoa_london)
``` 

Of course it should be of no surprise that our `msoa_lon` spatial dataframe is in **OSGB36 / British National Grid **, however, it is always good to check. Let's go ahead and read in our `tfl_stations` dataset as well:

```{r}
#| label: 06-load-stations
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# load stations
stations_london <- read_sf("data/raw/transport/tfl_stations.kml")
``` 

This dataset is provided as a `kml` file, which stands for **Keyhole Markup Language (KML)**.  KML was originally created as a file format used to display geographic data in Google Earth. So we definitely need to check what CRS this dataset is in and decide whether we will need to do some reprojecting.

```{r}
#| label: 06-crs-stations
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect CRS
st_crs(stations_london)
``` 

The result informs us that we are going to need to reproject our data in order to use this dataframe with our `msoa_london` spatial dataframe. Luckily in **R** and the `sf` library, this reprojection is a relatively straightforward transformation, requiring only one function: `st_transform()`. The function is very simple to use: you only need to provide the function with the dataset and the code for the new CRS you wish to use with the data:

```{r}
#| label: 06-crs-transform
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# reproject our data from WGS84 to BNG
stations_london <- st_transform(stations_london, 27700)
``` 

We can double-check whether our new variable is in the correct CRS by using the `st_crs()` command:

```{r}
#| label: 06-crs-stations-after-trans
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect CRS
st_crs(stations_london)
``` 

You should see that our `london_stations` spatial dataframe is now in **OSGB36 / British National Grid**. We are now ready to load our final dataset - our collection of `csv's` that contain the crimedata for London for 2021. We can do this by repeating the steps we took during [Week 4's computer tutorial](04-statistics.html#crime-data):

```{r tidy="styler"}
#| label: 06-combine-csv
#| classes: styled-output
#| echo: True
#| eval: True
#| message: False
#| filename: "R code"
# create a list of all csv files in the crime folder
all_crime_df <- list.files(path="data/raw/crime/all-crime/", full.names=TRUE, recursive=TRUE) |>
  # apply the read_csv() function on each of these files
  lapply(read_csv) |>
  # combine ('bind') them all together into one
  bind_rows()
```

Now we have loaded all crime data again, we want to do three things:

1. Extract only those crimes that are bicycle thefts.
2. Convert our `csv` into a spatial dataframe that shows the locations of our crimes, as per the latitude and longitudes provided.
3. Transform our data from **WGS84 / 4326** to **BNG / 27700**.

```{r tidy="styler"}
#| label: 06-bike-theft
#| classes: styled-output
#| echo: True
#| eval: True
#| message: False
#| filename: "R code"
# filter all crimes by bicycle thefts only
bike_theft <- all_crime_df |>
  # filter according to crime type, filter out crimes with no location data
  filter(`Crime type` == "Bicycle theft" & !is.na(Longitude) & !is.na(Latitude)) |>
  # only keep the longitude and latitude columns
  dplyr::select(Longitude, Latitude) |>
  # transform into a point spatial dataframe, projected in WGS84
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4236) |>
  # transform into BNG
  st_transform(27700)
``` 

We now have our three datasets loaded, it is time for a little data checking. We can see just from our **Environment** window that in total, we have **302** train and tube stations and **20,768** crimes to look at in our analysis. We can double-check the (Attribute) tables of our newly created spatial dataframes to see what data we have to work with. You can either do this manually by clicking on the variable, or using commands such as `head()`, `summary()` and `names()` to get an understanding of our dataframe structures and the field names present.You can choose your approach, but make sure to look at your data.

As you should remember from the code above, for our bicycle theft data, we actually only have our geometry column because this is all that we extracted from our collection of crime `csv's`. For our `stations_london` spatial dataframe, we have a little more information, including the name of the station, its address, and as its geometry.

Now, let's map all three layers of data onto a single map using `tmap`:
