# Programming for Spatial Analysis
This week we are going to look at how to use R and RStudio as a piece of GIS software. Like last week, we will be completing an analysis on our London theft crime dataset. However, rather than solely looking at crime by month , we will add a spatial component to our analysis.

## Lecture slides {#slides-w05}
The slides for this week's lecture can be downloaded here: [\[Link\]]({{< var slides.week05 >}})

## Reading list {#reading-w05}
#### Essential readings
- Longley, P. *et al.* 2015. Geographic Information Science & systems, **Chapter 13**: *Spatial Analysis*, pp. 290-318. [[Link]](https://ucl.rl.talis.com/link?url=https%3A%2F%2Fapp.knovel.com%2Fhotlink%2Ftoc%2Fid%3AkpGISSE001%2Fgeographic-information-science%3Fkpromoter%3Dmarc&sig=e437927b963cc591dcb65491eccdd3869cc31aef80e1443cb2ba12d8f3bb031a)
- Lovelace, R., Nowosad, J. and Muenchow, J. 2021. Geocomputation with R, **Chapter 2**: *Geographic Data in R*. [[Link]](https://geocompr.robinlovelace.net/spatial-class.html)
- Lovelace, R., Nowosad, J. and Muenchow, J. 2021. Geocomputation with R, **Chapter 3**: *Attribute data operations*. [[Link]](https://geocompr.robinlovelace.net/attr.html)
- Lovelace, R., Nowosad, J. and Muenchow, J. 2021. Geocomputation with R, **Chapter 8**: *Making maps with R*. [[Link]](https://geocompr.robinlovelace.net/adv-map.html)

#### Suggested readings 
- Poorthuis, A. and Zook, M. 2020. Being smarter about space: Drawing lessons from spatial science. *Annals of the American Association of Geographers* 110(2): 349-359. [[Link]](https://doi.org/10.1080/24694452.2019.1674630)
- De Smith, M, Goodchild, M. and Longley, P. 2018. Geospatial analsyis. A Comprehensive guide to principles techniques and software tools. **Chapter 9**: *Big Data and geospatial analysis*. [[Link]](https://arxiv.org/pdf/1902.06672.pdf)
- Radil, S. 2016. Spatial analysis of crime. **Chapter 24**: *The Handbook of Measurement Issues in Criminology and Criminal Justice*, pp. 536-554. [[Link]](https://doi.org/10.1002/9781118868799.ch24)

## Crime in London III
To analyse crime over time, we will go through several steps of data preparation before joining our data to LSOA polygons. Because theft by month, by LSOA, may result in a rather sparsely populated map, we will also **aggregate** our LSOA data to the **Middle layer Super Output Area** (MSOA) level. After this, we will map the crime rate for January 2021 using the `tmap` library.

::: { .callout-note}
OAs, LSOAs and MSOAs make up the different levels of the census statistical geographies. Middle layer Super Output Areas (MSOAs) are made up of groups of LSOAs, usually four or five. They comprise between 2,000 and 6,000 households and have a usually resident population between 5,000 and 15,000 persons. For details see the explanation on the webapge of the [Office for National Statistics](https://www.ons.gov.uk/methodology/geography/ukgeographies/censusgeographies/census2021geographies#middle-layer-super-output-areas-msoas)
:::

### Spatial analysis set up
Open a new script within your GEOG0030 project and save this script as `wk5-crime-spatial-processing.r`. At the top of your script, add the following metadata:

```{r}
#| label: 05-script-title
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: False
#| filename: "R code"
# Analysing theft in London by month, by MSOA
# Date: January 2024
# Author: Justin 
```

Now let us add **all** of the libraries we will be using today to the top of our script:

```{r}
#| label: 05-load-libraries
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# load libraries
library(tidyverse)
library(sf)
library(tmap)
```

```{r}
#| label: 05-tmap-settings
#| classes: styled-output
#| echo: False
#| warning: False
#| message: False
#| eval: True
# ensure tmap is set to plot
tmap_mode("plot")
```

You have already been introduced to the `tidyverse` library last week, but now we are adding `sf` to read and load our spatial data as well as `tmap` to visualise our spatial data. We are going to first load the `crime-theft-2021-london.csv` we saved last week.

```{r}
#| label: 05-load-csv
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# read in our csv file
all_theft_df <- read_csv("data/raw/crime/crime-theft-2021-london.csv")
``` 

Because some of the crimes do not have a location associated with them, we will filter these out as well: 

```{r}
#| label: 05-filter-them-no-locs
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# filter out crimes that have no location information
all_theft_df <- filter(all_theft_df, location != "No Location")
``` 

We can double-check what our `csv` looks like by either viewing our data or simply calling the `head()` function on our dataframe:
 
```{r}
#| label: 05-head-csv
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect
head(all_theft_df)
``` 

You should see these rows display in your console. Great, the dataset looks as we remember. Next, we need a dataset containing the **MSOAs** for London. Normally, you would navigate to the [Open Geography Portal](https://geoportal.statistics.gov.uk/), download a copy of all MSOA file, and filter out the MSOAs that you need. To save us some time today, you can download a pre-filtered MSOA file below. Unzip the file and copy the `GeoPackage` into your `data/raw/boundaries` folder.

| File                     | Type         | Link |
| :------                  | :------      | :------ |
| MSOAs London 2021        | `GeoPackage` |    [Download](https://github.com/jtvandijk/GEOG0030/tree/master/data/zip/msoa2021-london.zip) |

Now let's load the `MSOA2021_London.gpkg`. We will store this as a variable called `msoa_population` and use the `sf` library to load the data:

```{r}
#| label: 05-load-shp
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# read in our MSOA GeoPackage
msoa_population <- st_read("data/raw/boundaries/MSOA2021_London.gpkg")
``` 

You should also see the `msoa_population` variable appear in your environment window.

### Interacting with spatial data
As this is the first time we have loaded spatial data into R, let's go for a little exploration of how we can interact with our spatial dataframe. The first thing we want to do when we load spatial data is, of course, map it to confirm if everything is in order. To do this, we can use a really simple command from Râ€™s `base` library: `plot()`. As we do not necessarily want to plot this data everytime we run this script in the future, we can type this command into the console:

```{r}
#| label: 05-plot-msoapop
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| cache: True
#| filename: "R code"
# plot our MSOA data
plot(msoa_population)
``` 

You should see your `msoa_population` plot appear in your **Plots** window. As you will see, your MSOA dataset is plotted 'thematically' by each of the fields within the dataset, including the `pop2021` field. 

::: { .callout-warning}
This `plot()` function is not to be used to make maps but can be used as a quick way of viewing our spatial data.
:::

We canfind out more information about our `msoa_population` data. Let's next check out our class of our data. Again, **in the console** type:

```{r}
#| label: 05-maxprint
#| echo: False
#| eval: True
options(max.print=100)
``` 

```{r}
#| label: 05-class-msoapop
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect
class(msoa_population)
``` 

We should see our data is an `sf` dataframe, which is great because it means we can utilise our `tidyverse` libraries with our `msoa_population`. We can also use the `attributes()` function we looked at last week to find out a little more about the spatial part of our dataframe:

```{r}
#| label: 05-att-msoapop
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect
attributes(msoa_population)
``` 

We can see how many rows we have, the names of our rows and a few more pieces of information about our `msoa_population` data, for example, we can see that the specific `$sf_column` i.e. our spatial information) in our dataset is called `geom`.

We can investigate this column a little more by **selecting** this column within our console to return. In the **console** type:

```{r}
#| label: 05-geom-msoapop
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect geometry column
msoa_population$geom
``` 

You should see new information about our `geom` column display in your console. From this selection we can find out the dataset's:

- geometry type
- dimension
- `bbox` (bounding box)
- CRS (coordinate reference system)
- definition of the first five geometries of the dataset

This is really useful as one of the first things we want to know about our spatial data is what *coordinate system* it is projected with. As we should know, our `msoa_population` data was created and exported within *British National Grid*, therefore seeing this confirmed by the information stored in the `geom` data tells us that R has read in our dataset correctly.

We can also find out this information using the `st_crs()` function from the `sf` library.

```{r}
#| label: 05-crs-msoapop
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect CRS
st_crs(msoa_population)
``` 

You notice that we actually get a lot more information about our CRS beyond simply the code using this function. This function is really important to us as users of spatial data as it allows us to retrieve and set the CRS of our spatial data when the projection is not specified in the data but we do know what projection system should be used.

The final thing we might want to do before we get started with our data analysis is to simply look at the data table part of our dataset, i.e. what we called the **Attribute Table** in QGIS, but here it is simply the table part of our dataframe. To do so, you can either use the `View()` function in the console or click on the `msoa_population` variable within our environment.

### Getting our crime data into shape
Now we have our data loaded, our next step is to process our data to create what we need as our final output for analysis: a spatial dataframe that contains a **theft crime rate** for each MSOA for each month in 2021. We only two types of spatial or spatially-relevant data in our `all_theft_df` that can help us with this:

1) The approximate WGS84 **latitude** and **longitude**.
2) The **Lower Super Output Area (LSOA)** in which the crime it occurred.

From Week 3's practical, we know we can map our points using the coordinates and then provide a count by using a **point-in-polygon** operation, but because the crime data already have an LSOA code we will be using an **Attribute Join** today, after aggregating the LSOA geographies to MSOA geograhpies.

::: { .callout-note}
In situations like this when you actually have the point location data, the most accurate solution is to conduct a point-in-polygon analysis. However, because we do not always have access to point location data and you are likely to encounter situations where you need a **lookup** table, we will proceed with our **Attribute Join**
:::

